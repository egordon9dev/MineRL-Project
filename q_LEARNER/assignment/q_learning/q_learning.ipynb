{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning & DQNs (12 regular points + 2 extra credit points for both CS4803 and CS7643)\n",
    "\n",
    "In this section, we will implement a few key parts of the Q-Learning algorithm for two cases - (1) A Q-network which is a single linear layer (referred to in RL literature as \"Q-learning with linear function approximation\") and (2) A deep (convolutional) Q-network, for some Atari game environments where the states are images.\n",
    "\n",
    "Optional Readings: \n",
    "- **Playing Atari with Deep Reinforcement Learning**, Mnih et. al., https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "- **The PyTorch DQN Tutorial** https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minerl2/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from core.dqn_train import DQNTrain\n",
    "from utils.test_env import EnvTest\n",
    "from utils.schedule import LinearExploration, LinearSchedule\n",
    "from utils.preprocess import greyscale\n",
    "from utils.wrappers import PreproWrapper, MaxAndSkipEnv\n",
    "\n",
    "from linear_qnet import LinearQNet\n",
    "from cnn_qnet import ConvQNet\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda', 0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "import minerl\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting Minecraft process: ['/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/launchClient.sh', '-port', '9016', '-env', '-runDir', '/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/run']\n",
      "Starting process watcher for process 33998 @ localhost:9016\n",
      "This mapping 'snapshot_20161220' was designed for MC 1.11! Use at your own peril.\n",
      "#################################################\n",
      "         ForgeGradle 2.2-SNAPSHOT-3966cea        \n",
      "  https://github.com/MinecraftForge/ForgeGradle  \n",
      "#################################################\n",
      "               Powered by MCP unknown               \n",
      "             http://modcoderpack.com             \n",
      "         by: Searge, ProfMobius, Fesh0r,         \n",
      "         R4wk, ZeuX, IngisKahn, bspkrs           \n",
      "#################################################\n",
      "Found AccessTransformer: malmomod_at.cfg\n",
      ":deobfCompileDummyTask\n",
      ":deobfProvidedDummyTask\n",
      ":getVersionJson\n",
      ":extractUserdev\n",
      ":downloadClient SKIPPED\n",
      ":downloadServer SKIPPED\n",
      ":splitServerJar SKIPPED\n",
      ":mergeJars SKIPPED\n",
      ":applyBinaryPatches\n",
      ":extractDependencyATs SKIPPED\n",
      ":extractMcpData SKIPPED\n",
      ":extractMcpMappings SKIPPED\n",
      ":genSrgs SKIPPED\n",
      ":deobfMcMCP\n",
      "Applying SpecialSource...\n",
      "Applying Exceptor...\n",
      "Applying RuntimeInvisibleParameterAnnotations workaround...\n",
      ":sourceApiJava\n",
      ":compileApiJava UP-TO-DATE\n",
      ":processApiResources UP-TO-DATE\n",
      ":apiClasses UP-TO-DATE\n",
      ":copyModToClient UP-TO-DATE\n",
      ":copyModToServer UP-TO-DATE\n",
      ":copySrg\n",
      ":deleteSchemas\n",
      ":copySchemas\n",
      ":jaxb\n",
      ":sourceMainJava\n",
      ":compileJavawarning: [options] bootstrap class path not set in conjunction with -source 1.6\n",
      "Note: SpongePowered MIXIN Annotation Processor Version=0.7.5\n",
      "Note: ObfuscationServiceMCP supports type: \"searge\"\n",
      "Note: ObfuscationServiceMCP supports type: \"notch\"\n",
      "Note: Loading searge mappings from /Users/maxrudolph/.gradle/caches/minecraft/de/oceanlabs/mcp/mcp_snapshot/20161220/1.11.2/srgs/mcp-srg.srg\n",
      "Note: Loading notch mappings from /Users/maxrudolph/.gradle/caches/minecraft/de/oceanlabs/mcp/mcp_snapshot/20161220/1.11.2/srgs/mcp-notch.srg\n",
      "Note: Writing refmap to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/compileJava-refmap.json\n",
      "Note: Writing refmap to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/compileJava-refmap.json\n",
      "Note: Writing searge output SRGs to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/mcp-srg.srg\n",
      "Note: Writing notch output SRGs to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/mcp-notch.srg\n",
      "Note: Writing refmap to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/compileJava-refmap.json\n",
      "Note: Writing refmap to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/compileJava-refmap.json\n",
      "Note: Writing searge output SRGs to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/mcp-srg.srg\n",
      "Note: Writing notch output SRGs to /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/tmp/compileJava/mcp-notch.srg\n",
      "Note: Some input files use or override a deprecated API.\n",
      "Note: Recompile with -Xlint:deprecation for details.\n",
      "Note: Some input files use unchecked or unsafe operations.\n",
      "Note: Recompile with -Xlint:unchecked for details.\n",
      "\n",
      ":processResources\n",
      ":classes\n",
      ":jar\n",
      ":extractNatives SKIPPED\n",
      ":getAssetIndex UP-TO-DATE\n",
      ":getAssets\n",
      ":makeStart SKIPPED\n",
      ":runClient\n",
      "[09:57:34] [main/INFO]: Extra: []\n",
      "[09:57:34] [main/INFO]: Found and added coremod: com.microsoft.Malmo.OverclockingPlugin\n",
      "[09:57:34] [main/INFO]: Running with arguments: [--userProperties, {}, --assetsDir, /Users/maxrudolph/.gradle/caches/minecraft/assets, --assetIndex, 1.11, --accessToken{REDACTED}, --version, 1.11.2, --tweakClass, net.minecraftforge.fml.common.launcher.FMLTweaker, --tweakClass, net.minecraftforge.gradle.tweakers.CoremodTweaker]\n",
      "[09:57:34] [main/INFO]: Loading tweak class name net.minecraftforge.fml.common.launcher.FMLTweaker\n",
      "[09:57:34] [main/INFO]: Using primary tweak class name net.minecraftforge.fml.common.launcher.FMLTweaker\n",
      "[09:57:34] [main/INFO]: Loading tweak class name net.minecraftforge.gradle.tweakers.CoremodTweaker\n",
      "[09:57:34] [main/INFO]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLTweaker\n",
      "[09:57:34] [main/INFO]: Forge Mod Loader version 13.20.0.2228 for Minecraft 1.11.2 loading\n",
      "[09:57:34] [main/INFO]: Java is OpenJDK 64-Bit Server VM, version 1.8.0_272, running on Mac OS X:x86_64:10.15.7, installed at /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre\n",
      "[09:57:34] [main/INFO]: Managed to load a deobfuscated Minecraft name- we are in a deobfuscated environment. Skipping runtime deobfuscation\n",
      "[09:57:34] [main/INFO]: Found a command line coremod : com.microsoft.Malmo.OverclockingPlugin\n",
      "[09:57:34] [main/WARN]: The coremod com.microsoft.Malmo.OverclockingPlugin does not have a MCVersion annotation, it may cause issues with this version of Minecraft\n",
      "[09:57:34] [main/INFO]: SpongePowered MIXIN Subsystem Version=0.7.5 Source=file:/Users/maxrudolph/.gradle/caches/modules-2/files-2.1/org.spongepowered/mixin/0.7.5-SNAPSHOT/c989878008c2c5ff1a7c6491c4103d8faa221d19/mixin-0.7.5-SNAPSHOT.jar Service=LaunchWrapper Env=CLIENT\n",
      "[09:57:34] [main/INFO]: Compatibility level set to JAVA_8\n",
      "[09:57:34] [main/INFO]: Calling tweak class net.minecraftforge.gradle.tweakers.CoremodTweaker\n",
      "[09:57:34] [main/INFO]: Injecting location in coremod net.minecraftforge.fml.relauncher.FMLCorePlugin\n",
      "[09:57:34] [main/INFO]: Injecting location in coremod net.minecraftforge.classloading.FMLForgePlugin\n",
      "[09:57:34] [main/INFO]: Injecting location in coremod com.microsoft.Malmo.OverclockingPlugin\n",
      "[09:57:34] [main/INFO]: Loading tweak class name net.minecraftforge.fml.common.launcher.FMLInjectionAndSortingTweaker\n",
      "[09:57:34] [main/INFO]: Loading tweak class name org.spongepowered.asm.mixin.EnvironmentStateTweaker\n",
      "[09:57:34] [main/INFO]: Loading tweak class name net.minecraftforge.fml.common.launcher.FMLDeobfTweaker\n",
      "[09:57:34] [main/INFO]: Loading tweak class name net.minecraftforge.gradle.tweakers.AccessTransformerTweaker\n",
      "[09:57:34] [main/INFO]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLInjectionAndSortingTweaker\n",
      "[09:57:34] [main/INFO]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLInjectionAndSortingTweaker\n",
      "[09:57:34] [main/INFO]: Calling tweak class net.minecraftforge.fml.relauncher.CoreModManager$FMLPluginWrapper\n",
      "[09:57:34] [main/ERROR]: The binary patch set is missing. Either you are in a development environment, or things are not going to work!\n",
      "[09:57:35] [main/ERROR]: FML appears to be missing any signature data. This is not a good thing\n",
      "[09:57:35] [main/INFO]: Calling tweak class net.minecraftforge.fml.relauncher.CoreModManager$FMLPluginWrapper\n",
      "[09:57:35] [main/INFO]: Calling tweak class net.minecraftforge.fml.relauncher.CoreModManager$FMLPluginWrapper\n",
      "[09:57:35] [main/INFO]: Calling tweak class org.spongepowered.asm.mixin.EnvironmentStateTweaker\n",
      "[09:57:35] [main/INFO]: Initialised Mixin FML Remapper Adapter with net.minecraftforge.fml.common.asm.transformers.deobf.FMLDeobfuscatingRemapper@75201592\n",
      "[09:57:35] [main/INFO]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLDeobfTweaker\n",
      "[09:57:35] [main/INFO]: Calling tweak class net.minecraftforge.gradle.tweakers.AccessTransformerTweaker\n",
      "[09:57:35] [main/INFO]: Loading tweak class name net.minecraftforge.fml.common.launcher.TerminalTweaker\n",
      "[09:57:35] [main/INFO]: Calling tweak class net.minecraftforge.fml.common.launcher.TerminalTweaker\n",
      "[09:57:35] [main/WARN]: Reference map 'mixins.replaymod.refmap.json' for mixins.overclocking.malmomod.json could not be read. If this is a development environment you can ignore this message\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:58]: MALMO: Attempting to transform MinecraftServer\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:129]: MALMO: Found Minecraft, attempting to transform it\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:135]: MALMO: Found Minecraft.runGameLoop() method, attempting to transform it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:150]: MALMO: Hooked into call to Minecraft.updateDisplay()\n",
      "[09:57:35] [main/INFO]: A re-entrant transformer '$wrapper.com.microsoft.Malmo.OverclockingClassTransformer' was detected and will no longer process meta class data\n",
      "[09:57:35] [main/INFO]: Launching wrapped minecraft {net.minecraft.client.main.Main}\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:58]: MALMO: Attempting to transform MinecraftServer\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:129]: MALMO: Found Minecraft, attempting to transform it\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:135]: MALMO: Found Minecraft.runGameLoop() method, attempting to transform it\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:150]: MALMO: Hooked into call to Minecraft.updateDisplay()\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:42]: Transformed Name: net.minecraft.client.entity.EntityPlayerSP\n",
      "[09:57:35] [main/INFO]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:42]: Transformed Name: net.minecraft.client.entity.AbstractClientPlayer\n",
      "[09:57:36] [Client thread/INFO]: Setting user: Player437\n",
      "[09:57:39] [Client thread/WARN]: Skipping bad option: lastServer:\n",
      "[09:57:39] [Client thread/INFO]: LWJGL Version: 2.9.2\n",
      "[09:57:39] [Client thread/INFO]: [STDOUT]: MALMO: Attempting to transform MinecraftServer\n",
      "[09:57:39] [Client thread/INFO]: [STDOUT]: MALMO: Found GlStateManager, attempting to transform it\n",
      "[09:57:39] [Client thread/INFO]: [STDOUT]: MALMO: Found GlStateManager.bindTexture() method, attempting to transform it\n",
      "[09:57:39] [Client thread/INFO]: [STDOUT]: MALMO: Hooked into call to GlStateManager.bindTexture()\n",
      "[09:57:39] [Client thread/INFO]: MinecraftForge v13.20.0.2228 Initialized\n",
      "[09:57:40] [Client thread/INFO]: Replaced 232 ore recipes\n",
      "[09:57:40] [Client thread/INFO]: Found 0 mods from the command line. Injecting into mod discoverer\n",
      "[09:57:40] [Client thread/INFO]: Searching /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/run/mods for mods\n",
      "[09:57:41] [Client thread/INFO]: Forge Mod Loader has identified 5 mods to load\n",
      "[09:57:41] [Client thread/INFO]: Attempting connection with missing mods [minecraft, mcp, FML, forge, malmomod] at CLIENT\n",
      "[09:57:41] [Client thread/INFO]: Attempting connection with missing mods [minecraft, mcp, FML, forge, malmomod] at SERVER\n",
      "[09:57:41] [Client thread/INFO]: Reloading ResourceManager: Default, FMLFileResourcePack:Forge Mod Loader, FMLFileResourcePack:Minecraft Forge, FMLFileResourcePack:Microsoft Malmo Mod\n",
      "[09:57:41] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/libs/MalmoMod-0.37.0.jar\n",
      "[09:57:41] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/libs/MalmoMod-0.37.0.jar\n",
      "[09:57:41] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/libs/MalmoMod-0.37.0.jar\n",
      "[09:57:41] [Client thread/INFO]: Processing ObjectHolder annotations\n",
      "[09:57:41] [Client thread/INFO]: Found 444 ObjectHolder annotations\n",
      "[09:57:41] [Client thread/INFO]: Identifying ItemStackHolder annotations\n",
      "[09:57:41] [Client thread/INFO]: Found 0 ItemStackHolder annotations\n",
      "[09:57:41] [Client thread/INFO]: Applying holder lookups\n",
      "[09:57:41] [Client thread/INFO]: Holder lookups applied\n",
      "[09:57:41] [Client thread/INFO]: Applying holder lookups\n",
      "[09:57:41] [Client thread/INFO]: Holder lookups applied\n",
      "[09:57:41] [Client thread/INFO]: Applying holder lookups\n",
      "[09:57:41] [Client thread/INFO]: Holder lookups applied\n",
      "[09:57:41] [Client thread/INFO]: Configured a dormant chunk cache size of 0\n",
      "[09:57:41] [Forge Version Check/INFO]: [forge] Starting version check at http://files.minecraftforge.net/maven/net/minecraftforge/forge/promotions_slim.json\n",
      "[09:57:41] [Client thread/INFO]: [STDOUT]: Testing schemas against internal version number: 0.37\n",
      "[09:57:42] [Forge Version Check/INFO]: [forge] Found status: OUTDATED Target: 13.20.1.2386\n",
      "[09:57:42] [Client thread/INFO]: [STDOUT]: [LOGTOPY] Performance directory not specified.\n",
      "[09:57:42] [Client thread/INFO]: [STDOUT]: [ERROR] Seed specified was NONE. Expected a long (integer).\n",
      "[09:57:42] [Client thread/INFO]: Applying holder lookups\n",
      "[09:57:42] [Client thread/INFO]: Holder lookups applied\n",
      "[09:57:42] [Client thread/INFO]: Injecting itemstacks\n",
      "[09:57:42] [Client thread/INFO]: Itemstack injection complete\n",
      "[09:57:43] [Sound Library Loader/INFO]: Starting up SoundSystem...\n",
      "[09:57:43] [Thread-5/INFO]: Initializing LWJGL OpenAL\n",
      "[09:57:43] [Thread-5/INFO]: (The LWJGL binding of OpenAL.  For more information, see http://www.lwjgl.org)\n",
      "[09:57:43] [Thread-5/INFO]: OpenAL initialized.\n",
      "[09:57:44] [Sound Library Loader/INFO]: Sound engine started\n",
      "[09:57:45] [Client thread/INFO]: Max texture size: 16384\n",
      "[09:57:45] [Client thread/INFO]: Created: 16x16 textures-atlas\n",
      "[09:57:45] [Client thread/INFO]: [STDOUT]: CLIENT request state: WAITING_FOR_MOD_READY\n",
      "[09:57:46] [Client thread/INFO]: Injecting itemstacks\n",
      "[09:57:46] [Client thread/INFO]: Itemstack injection complete\n",
      "[09:57:46] [Client thread/INFO]: Forge Mod Loader has successfully loaded 5 mods\n",
      "[09:57:46] [Client thread/INFO]: Reloading ResourceManager: Default, FMLFileResourcePack:Forge Mod Loader, FMLFileResourcePack:Minecraft Forge, FMLFileResourcePack:Microsoft Malmo Mod\n",
      "[09:57:46] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/libs/MalmoMod-0.37.0.jar\n",
      "[09:57:46] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/libs/MalmoMod-0.37.0.jar\n",
      "[09:57:46] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /private/var/folders/_5/9n4k6nj50nb48gfy7_x3brnr0000gn/T/tmpjwt17x8w/Minecraft/build/libs/MalmoMod-0.37.0.jar\n",
      "[09:57:46] [Client thread/INFO]: SoundSystem shutting down...\n",
      "[09:57:47] [Client thread/WARN]: Author: Paul Lamb, www.paulscode.com\n",
      "[09:57:47] [Sound Library Loader/INFO]: Starting up SoundSystem...\n",
      "[09:57:47] [Thread-7/INFO]: Initializing LWJGL OpenAL\n",
      "[09:57:47] [Thread-7/INFO]: (The LWJGL binding of OpenAL.  For more information, see http://www.lwjgl.org)\n",
      "[09:57:47] [Thread-7/INFO]: OpenAL initialized.\n",
      "[09:57:47] [Sound Library Loader/INFO]: Sound engine started\n",
      "[09:57:48] [Client thread/INFO]: Max texture size: 16384\n",
      "[09:57:48] [Client thread/INFO]: Created: 512x512 textures-atlas\n",
      "[09:57:49] [Client thread/WARN]: Skipping bad option: lastServer:\n",
      "[09:57:49] [Client thread/INFO]: [STDOUT]: CLIENT enter state: WAITING_FOR_MOD_READY\n",
      "[09:57:49] [Client thread/INFO]: [STDOUT]: ***** Start MalmoEnvServer on port 9016\n",
      "[09:57:49] [Client thread/INFO]: [STDOUT]: CLIENT request state: DORMANT\n",
      "[09:57:49] [Client thread/INFO]: [STDOUT]: CLIENT enter state: DORMANT\n",
      "Minecraft process ready\n",
      "Logging output of Minecraft to ./logs/mc_16.log\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dict' object has no attribute 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fc7fbf971f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearQNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_lin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CLASSES/CS4803/cs4803_final_project/hw5/assignment/q_learning/core/dqn_train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, q_net_class, env, config, device, logger)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_net_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_q_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_net_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CLASSES/CS4803/cs4803_final_project/hw5/assignment/q_learning/linear_qnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, config)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# * config.state_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dict' object has no attribute 'n'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:57:51] [Realms Notification Availability checker #1/INFO]: Could not authorize you against Realms server: Invalid session id\n"
     ]
    }
   ],
   "source": [
    "from configs.p1_linear import config as config_lin\n",
    "\n",
    "env = gym.make('MineRLTreechop-v0')\n",
    "\n",
    "# exploration strategy\n",
    "exp_schedule = LinearExploration(env, config_lin.eps_begin,\n",
    "        config_lin.eps_end, config_lin.eps_nsteps)\n",
    "\n",
    "# learning rate schedule\n",
    "lr_schedule  = LinearSchedule(config_lin.lr_begin, config_lin.lr_end,\n",
    "        config_lin.lr_nsteps)\n",
    "\n",
    "# train model\n",
    "model = DQNTrain(LinearQNet, env, config_lin, device)\n",
    "model.run(exp_schedule, lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a final average reward of over 4.0 on the test environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Q-Learning with Deep Q-Networks\n",
    "\n",
    "In `cnn_qnet.py`, implement the initialization and forward pass of a convolutional Q-network with architecture as described in this DeepMind paper:\n",
    "    \n",
    "\"Playing Atari with Deep Reinforcement Learning\", Mnih et. al. (https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)\n",
    "\n",
    "### Deliverable 2 (4 points)\n",
    "\n",
    "Run the following block of code to train our Deep Q-Network. You should get an average reward of ~4.0, full credit will be given if average reward at the final evaluation is above 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Average reward: 0.50 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the memory 150/200..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average reward: 0.50 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 301/1000 [========>.....................] - ETA: 2s - Loss: 0.8469 - Avg_R: 0.0300 - Max_R: 1.9000 - eps: 0.4060 - Grads: 6.8221 - Max_Q: 0.2089 - lr: 0.0002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Average reward: -0.80 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 401/1000 [===========>..................] - ETA: 3s - Loss: 0.4634 - Avg_R: -0.0950 - Max_R: 1.9000 - eps: 0.2080 - Grads: 6.8951 - Max_Q: 0.2849 - lr: 0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average reward: -1.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 501/1000 [==============>...............] - ETA: 2s - Loss: 0.4247 - Avg_R: 1.3750 - Max_R: 4.1000 - eps: 0.0100 - Grads: 7.0512 - Max_Q: 0.3212 - lr: 0.0001 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average reward: 1.40 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 601/1000 [=================>............] - ETA: 2s - Loss: 0.4257 - Avg_R: 2.9300 - Max_R: 4.1000 - eps: 0.0100 - Grads: 2.0311 - Max_Q: 0.5012 - lr: 0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Average reward: 2.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 701/1000 [====================>.........] - ETA: 2s - Loss: 0.9208 - Avg_R: 2.4700 - Max_R: 4.1000 - eps: 0.0100 - Grads: 10.4751 - Max_Q: 0.7719 - lr: 0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Average reward: 4.10 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 801/1000 [=======================>......] - ETA: 1s - Loss: 0.5175 - Avg_R: 3.8950 - Max_R: 4.1000 - eps: 0.0100 - Grads: 6.3766 - Max_Q: 0.9394 - lr: 0.0001 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Average reward: 4.10 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 901/1000 [==========================>...] - ETA: 0s - Loss: 0.2690 - Avg_R: 3.9400 - Max_R: 4.1000 - eps: 0.0100 - Grads: 4.6875 - Max_Q: 1.0949 - lr: 0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Average reward: 4.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1001/1000 [==============================] - 7s - Loss: 0.1691 - Avg_R: 4.0600 - Max_R: 4.1000 - eps: 0.0100 - Grads: 5.5073 - Max_Q: 1.2369 - lr: 0.0001     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Training done.\n",
      "Evaluating...\n",
      "Average reward: 4.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from configs.p2_cnn import config as config_cnn\n",
    "\n",
    "env = EnvTest((80, 80, 1))\n",
    "\n",
    "# exploration strategy\n",
    "exp_schedule = LinearExploration(env, config_cnn.eps_begin,\n",
    "        config_cnn.eps_end, config_cnn.eps_nsteps)\n",
    "\n",
    "# learning rate schedule\n",
    "lr_schedule  = LinearSchedule(config_cnn.lr_begin, config_cnn.lr_end,\n",
    "        config_cnn.lr_nsteps)\n",
    "\n",
    "# train model\n",
    "model = DQNTrain(ConvQNet, env, config_cnn, device)\n",
    "model.run(exp_schedule, lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a final average reward of over 4.0 on the test environment, similar to the previous case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Playing Atari Games from Pixels - using Linear Function Approximation\n",
    "\n",
    "Now that we have setup our Q-Learning algorithm and tested it on a simple test environment, we will shift to a harder environment - an Atari 2600 game from OpenAI Gym: Pong-v0 (https://gym.openai.com/envs/Pong-v0/), where we will use RGB images of the game screen as our observations for state.\n",
    "\n",
    "No additional implementation is required for this part, just run the block of code below (will take around 1 hour to train). We don't expect a simple linear Q-network to do well on such a hard environment - full credit will be given simply for running the training to completion irrespective of the final average reward obtained.\n",
    "\n",
    "You may edit `configs/p3_train_atari_linear.py` if you wish to play around with hyperparamters for improving performance of the linear Q-network on Pong-v0, or try another Atari environment by changing the `env_name` hyperparameter. The list of all Gym Atari environments are available here: https://gym.openai.com/envs/#atari\n",
    "\n",
    "### Deliverable 3 (2 points)\n",
    "\n",
    "Run the following block of code to train a linear Q-network on Atari Pong-v0. We don't expect the linear Q-Network to learn anything meaingful so full credit will be given for simply running this training to completion (without errors), irrespective of the final average reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Q-Net Architecture:\n",
      " LinearQNet(\n",
      "  (fc_layer): Linear(in_features=25600, out_features=6, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average reward: -20.86 +/- 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250001/500000 [==============>...............] - ETA: 1145s - Loss: 0.1379 - Avg_R: -20.5600 - Max_R: -18.0000 - eps: 0.7750 - Grads: 11.1405 - Max_Q: 8.9496 - lr: 0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average reward: -20.96 +/- 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500001/500000 [==============================] - 2271s - Loss: 0.3513 - Avg_R: -20.6400 - Max_R: -19.0000 - eps: 0.5500 - Grads: 22.1367 - Max_Q: 8.7380 - lr: 0.0001  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- Training done.\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average reward: -20.38 +/- 0.10\n"
     ]
    }
   ],
   "source": [
    "from configs.p3_train_atari_linear import config as config_lina\n",
    "\n",
    "# make env\n",
    "env = gym.make(config_lina.env_name)\n",
    "env = MaxAndSkipEnv(env, skip=config_lina.skip_frame)\n",
    "env = PreproWrapper(env, prepro=greyscale, shape=(80, 80, 1),\n",
    "                    overwrite_render=config_lina.overwrite_render)\n",
    "\n",
    "# exploration strategy\n",
    "exp_schedule = LinearExploration(env, config_lina.eps_begin,\n",
    "        config_lina.eps_end, config_lina.eps_nsteps)\n",
    "\n",
    "# learning rate schedule\n",
    "lr_schedule  = LinearSchedule(config_lina.lr_begin, config_lina.lr_end,\n",
    "        config_lina.lr_nsteps)\n",
    "\n",
    "# train model\n",
    "model = DQNTrain(LinearQNet, env, config_lina, device)\n",
    "print(\"Linear Q-Net Architecture:\\n\", model.q_net)\n",
    "model.run(exp_schedule, lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Playing Atari Games from Pixels - using Deep Q-Networks\n",
    "\n",
    "This part is extra credit and worth 5 bonus points. We will now train our deep Q-Network from Part 2 on Pong-v0. \n",
    "\n",
    "Again, no additional implementation is required but you may wish to tweak your CNN architecture in `cnn_qnet.py` and hyperparameters in `configs/p4_train_atari_cnn.py` (however, evaluation will be considered at no farther than the default 5 million steps, so you are not allowed to train for longer). Please note that this training may take a very long time (we tested this on a single GPU and it took around 6 hours).\n",
    "\n",
    "The bonus points for this question will be allotted based on the best evaluation average reward (EAR) before 5 million time stpes:\n",
    "\n",
    "1. EAR >= 0.0 : 4/4 points\n",
    "2. EAR >= -5.0 : 3/4 points\n",
    "3. EAR >= -10.0 : 3/4 points\n",
    "4. EAR >= -15.0 : 1/4 points\n",
    "\n",
    "### Deliverable 4: (2 points. Extra Credit for both CS4803 and CS7643)\n",
    "\n",
    "Run the following block of code to train your DQN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from configs.p4_train_atari_cnn import config as config_cnna\n",
    "\n",
    "\n",
    "# make env\n",
    "env = gym.make(config_cnna.env_name)\n",
    "env = MaxAndSkipEnv(env, skip=config_cnna.skip_frame)\n",
    "env = PreproWrapper(env, prepro=greyscale, shape=(80, 80, 1),\n",
    "                    overwrite_render=config_cnna.overwrite_render)\n",
    "\n",
    "# exploration strategy\n",
    "exp_schedule = LinearExploration(env, config_cnna.eps_begin,\n",
    "        config_cnna.eps_end, config_cnna.eps_nsteps)\n",
    "\n",
    "# learning rate schedule\n",
    "lr_schedule  = LinearSchedule(config_cnna.lr_begin, config_cnna.lr_end,\n",
    "        config_cnna.lr_nsteps)\n",
    "\n",
    "# train model\n",
    "model = DQNTrain(ConvQNet, env, config_cnna, device)\n",
    "print(\"CNN Q-Net Architecture:\\n\", model.q_net)\n",
    "model.run(exp_schedule, lr_schedule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
